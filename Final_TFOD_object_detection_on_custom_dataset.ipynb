{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_TFOD_object_detection_on_custom_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VteKN_o1FqBV",
        "outputId": "58353ea0-5d27-40fb-b993-ee4fe90162ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.8\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.0%2Bzzzcolab20220506162203-cp37-cp37m-linux_x86_64.whl (668.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 668.3 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.47.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.5.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.14.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (14.0.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.17.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.8.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.26.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.8) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Successfully installed tensorflow-2.8.0+zzzcolab20220506162203 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 47 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 3,139 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 7s (63.8 MB/s)\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 155631 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znoKzdFAV1bL"
      },
      "outputs": [],
      "source": [
        "# If you forked the repository, you can replace the link.\n",
        "repo_url = 'https://github.com/Tony607/object_detection_demo'\n",
        "\n",
        "# Number of training steps.\n",
        "num_steps = 200000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "# MODELS_CONFIG = {\n",
        "#     'ssd_mobilenet_v2': {\n",
        "#         'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "#         'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "#         'batch_size': 12\n",
        "#     },\n",
        "#     'faster_rcnn_inception_v2': {\n",
        "#         'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "#         'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "#         'batch_size': 12\n",
        "#     },\n",
        "#     'rfcn_resnet101': {\n",
        "#         'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "#         'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "#         'batch_size': 8\n",
        "#     }\n",
        "# }\n",
        "MODELS_CONFIG = {\n",
        "    'efficientdet_d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'batch_size': 2 # Number of samples to process before updating values\n",
        "    },\n",
        "}\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'efficientdet_d0'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## clone the object detection demo repo\n"
      ],
      "metadata": {
        "id": "ZNcXthRBXdVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join(\".\",os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "\n",
        "%cd {repo_dir_path}\n",
        "\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS323y3oXP-c",
        "outputId": "e36aa79f-a754-443f-f659-0a421b89dd55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'object_detection_demo'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Total 124 (delta 0), reused 0 (delta 0), pack-reused 124\u001b[K\n",
            "Receiving objects: 100% (124/124), 11.16 MiB | 28.49 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n",
            "/content/object_detection_demo\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install required package\n"
      ],
      "metadata": {
        "id": "ohRnA8gGbJLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LLkUPtX0AuS",
        "outputId": "7462e829-a178-491f-aec9-3dcbabd30b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['PYTHONPATH'] += ':/content/models'"
      ],
      "metadata": {
        "id": "AdwsF8aN0DDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append( ':/content/models')"
      ],
      "metadata": {
        "id": "mkMMNnCi0OXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow-object-detection-api"
      ],
      "metadata": {
        "id": "hXuK57q0UaqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "# !pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "# !pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "%cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install --use-feature=2020-resolver .\n",
        "# import os\n",
        "# os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "# !python /content/models/research/object_detection/builders/model_builder_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FWLXhnPsR3l",
        "outputId": "6735568f-692a-41fe-8c8d-2f5e19b32666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n",
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.40.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 12.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.30)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 16.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 12.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 58.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 66.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 78.2 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 79 kB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 14.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Collecting tensorflow~=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.15)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting keras\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 72.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.47.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.6-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.5.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 57.2 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 76.7 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 74.3 MB/s \n",
            "\u001b[?25hCollecting orjson<4.0\n",
            "  Downloading orjson-3.7.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 75.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting cloudpickle<3,>=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.10)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.9.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.8.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1694955 sha256=b8539a4d46d1a6cc3c809a3d0347cfd72e5ccffca874944e1470997fc31a5b47\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-04cl2f__/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=ea08749f8566110c3d825b5bdc04fdd4695c72194442217deb6e803f3b73d697\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=250bb62f377d17136a00fabe4d6ec7f17e9ca40e1ccda20801b863e27bb05540\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=6b50840c88b889d6cbfe8a954dde54fec769c74238b07f0ae2cef0829b2112d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=eb4b4ac84ccb5411bfe33cbb89cde45afb674c2e7cba106b69b1541638db5d7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, pyparsing, protobuf, tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.1.1\n",
            "    Uninstalling pymongo-4.1.1:\n",
            "      Successfully uninstalled pymongo-4.1.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.13 requires dill>=0.3.5.1, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.40.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.5 dill-0.3.1.1 fastavro-1.5.3 flatbuffers-1.12 gast-0.4.0 hdfs-2.7.0 keras-2.9.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.6.0.66 orjson-3.7.8 portalocker-2.5.1 proto-plus-1.20.6 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.1.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-addons-0.17.1 tensorflow-estimator-2.9.0 tensorflow-io-0.26.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.9.0 tf-models-official-2.9.2 tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python /content/models/research/object_detection/builders/model_builder_test.py\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"
      ],
      "metadata": {
        "id": "oq8XZ4UJWJAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae491fa-2b84-41b3-91d3-50806b0bb548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-07-25 06:45:50.090256: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0725 06:45:50.572570 140225825019776 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.85s\n",
            "I0725 06:45:51.023463 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.85s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.0s\n",
            "I0725 06:45:52.028539 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.49s\n",
            "I0725 06:45:52.519964 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.49s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.47s\n",
            "I0725 06:45:52.985793 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.47s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.15s\n",
            "I0725 06:45:55.131821 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0725 06:45:55.132798 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0725 06:45:55.154978 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0725 06:45:55.169957 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0725 06:45:55.184380 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "I0725 06:45:55.276549 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "I0725 06:45:55.366948 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I0725 06:45:55.458194 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "I0725 06:45:55.549930 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "I0725 06:45:55.642940 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0725 06:45:55.674171 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0725 06:45:55.841174 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0725 06:45:55.841314 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0725 06:45:55.841387 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0725 06:45:55.843471 140225825019776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0725 06:45:55.860376 140225825019776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0725 06:45:55.860486 140225825019776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0725 06:45:55.926467 140225825019776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0725 06:45:55.926579 140225825019776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0725 06:45:56.082278 140225825019776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0725 06:45:56.082415 140225825019776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0725 06:45:56.235387 140225825019776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0725 06:45:56.235532 140225825019776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0725 06:45:56.468142 140225825019776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0725 06:45:56.468311 140225825019776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0725 06:45:56.855149 140225825019776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0725 06:45:56.855317 140225825019776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0725 06:45:57.167806 140225825019776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0725 06:45:57.167967 140225825019776 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0725 06:45:57.240000 140225825019776 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0725 06:45:57.271277 140225825019776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0725 06:45:57.318831 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0725 06:45:57.318955 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0725 06:45:57.319022 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0725 06:45:57.320499 140225825019776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0725 06:45:57.335839 140225825019776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0725 06:45:57.335939 140225825019776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0725 06:45:57.458032 140225825019776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0725 06:45:57.458157 140225825019776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0725 06:45:57.682601 140225825019776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0725 06:45:57.682769 140225825019776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0725 06:45:57.911373 140225825019776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0725 06:45:57.911526 140225825019776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0725 06:45:58.225330 140225825019776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0725 06:45:58.225494 140225825019776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0725 06:45:58.525054 140225825019776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0725 06:45:58.525220 140225825019776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0725 06:45:58.905975 140225825019776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0725 06:45:58.906151 140225825019776 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0725 06:45:59.065227 140225825019776 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0725 06:45:59.094527 140225825019776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0725 06:45:59.152210 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0725 06:45:59.152358 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0725 06:45:59.152443 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0725 06:45:59.153958 140225825019776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0725 06:45:59.171525 140225825019776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0725 06:45:59.171637 140225825019776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0725 06:45:59.290575 140225825019776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0725 06:45:59.290703 140225825019776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0725 06:45:59.520276 140225825019776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0725 06:45:59.520424 140225825019776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0725 06:45:59.747652 140225825019776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0725 06:45:59.747828 140225825019776 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0725 06:46:00.060228 140225825019776 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0725 06:46:00.060408 140225825019776 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0725 06:46:00.371943 140225825019776 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0725 06:46:00.372108 140225825019776 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0725 06:46:00.761799 140225825019776 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0725 06:46:00.761966 140225825019776 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0725 06:46:00.908923 140225825019776 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0725 06:46:00.936674 140225825019776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0725 06:46:01.003314 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0725 06:46:01.003464 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0725 06:46:01.003537 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0725 06:46:01.005186 140225825019776 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0725 06:46:01.021076 140225825019776 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0725 06:46:01.021197 140225825019776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0725 06:46:01.145032 140225825019776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0725 06:46:01.145169 140225825019776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0725 06:46:01.555016 140225825019776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0725 06:46:01.555207 140225825019776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0725 06:46:01.783156 140225825019776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0725 06:46:01.783310 140225825019776 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0725 06:46:02.172192 140225825019776 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0725 06:46:02.172353 140225825019776 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0725 06:46:02.545829 140225825019776 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0725 06:46:02.545985 140225825019776 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0725 06:46:03.014041 140225825019776 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0725 06:46:03.014256 140225825019776 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0725 06:46:03.168914 140225825019776 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0725 06:46:03.198715 140225825019776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0725 06:46:03.259793 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0725 06:46:03.259928 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0725 06:46:03.259995 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0725 06:46:03.261626 140225825019776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0725 06:46:03.277815 140225825019776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0725 06:46:03.277923 140225825019776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0725 06:46:03.400869 140225825019776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0725 06:46:03.400991 140225825019776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0725 06:46:03.707098 140225825019776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0725 06:46:03.707266 140225825019776 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0725 06:46:04.008054 140225825019776 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0725 06:46:04.008219 140225825019776 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0725 06:46:04.469141 140225825019776 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0725 06:46:04.469354 140225825019776 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0725 06:46:04.938463 140225825019776 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0725 06:46:04.938632 140225825019776 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0725 06:46:05.568795 140225825019776 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0725 06:46:05.568959 140225825019776 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0725 06:46:05.719973 140225825019776 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0725 06:46:05.747864 140225825019776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0725 06:46:05.823667 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0725 06:46:05.823824 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0725 06:46:05.823906 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0725 06:46:05.825432 140225825019776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0725 06:46:05.840737 140225825019776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0725 06:46:05.840852 140225825019776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0725 06:46:06.022059 140225825019776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0725 06:46:06.022194 140225825019776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0725 06:46:06.402599 140225825019776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0725 06:46:06.402781 140225825019776 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0725 06:46:06.981918 140225825019776 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0725 06:46:06.982093 140225825019776 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0725 06:46:07.546853 140225825019776 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0725 06:46:07.547017 140225825019776 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0725 06:46:08.093131 140225825019776 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0725 06:46:08.093310 140225825019776 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0725 06:46:08.786314 140225825019776 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0725 06:46:08.786488 140225825019776 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0725 06:46:09.015405 140225825019776 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0725 06:46:09.043818 140225825019776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0725 06:46:09.129969 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0725 06:46:09.130148 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0725 06:46:09.130231 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0725 06:46:09.132654 140225825019776 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0725 06:46:09.152370 140225825019776 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0725 06:46:09.152480 140225825019776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0725 06:46:09.335093 140225825019776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0725 06:46:09.335236 140225825019776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0725 06:46:09.794524 140225825019776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0725 06:46:09.794698 140225825019776 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0725 06:46:10.272419 140225825019776 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0725 06:46:10.272590 140225825019776 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0725 06:46:10.887002 140225825019776 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0725 06:46:10.887201 140225825019776 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0725 06:46:11.511831 140225825019776 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0725 06:46:11.512020 140225825019776 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0725 06:46:12.374119 140225825019776 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0725 06:46:12.374284 140225825019776 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0725 06:46:12.602182 140225825019776 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0725 06:46:12.633873 140225825019776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0725 06:46:12.941369 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0725 06:46:12.941530 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0725 06:46:12.941607 140225825019776 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0725 06:46:12.943115 140225825019776 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0725 06:46:12.959089 140225825019776 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0725 06:46:12.959201 140225825019776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0725 06:46:13.213248 140225825019776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0725 06:46:13.213447 140225825019776 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0725 06:46:13.753546 140225825019776 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0725 06:46:13.753726 140225825019776 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0725 06:46:14.313628 140225825019776 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0725 06:46:14.313816 140225825019776 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0725 06:46:15.081252 140225825019776 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0725 06:46:15.081428 140225825019776 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0725 06:46:15.859791 140225825019776 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0725 06:46:15.859958 140225825019776 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0725 06:46:16.865888 140225825019776 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0725 06:46:16.866058 140225825019776 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0725 06:46:17.179972 140225825019776 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0725 06:46:17.209275 140225825019776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 21.66s\n",
            "I0725 06:46:17.331126 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 21.66s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0725 06:46:17.336569 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0725 06:46:17.338127 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0725 06:46:17.338724 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0725 06:46:17.340132 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0725 06:46:17.341394 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0725 06:46:17.341835 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0725 06:46:17.342767 140225825019776 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 28.176s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mv /content/object_detection_demo/data/images/test /content/sample_data/"
      ],
      "metadata": {
        "id": "PAUcJwt5uHuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mv /content/object_detection_demo/data/images/train /content/sample_data/\n"
      ],
      "metadata": {
        "id": "qnITKZy31DhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir /content/object_detection_demo/data/images/train"
      ],
      "metadata": {
        "id": "ad_P-LGm1Op-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir /content/object_detection_demo/data/images/test"
      ],
      "metadata": {
        "id": "9_wzD1VL1ptf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls /content/object_detection_demo/data/raw"
      ],
      "metadata": {
        "id": "jhxuKWhX1uIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {repo_dir_path}\n",
        "\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jPtpKai2NXQ",
        "outputId": "adf39b52-8553-4370-a8be-cc32fc2867ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/object_detection_demo\n",
            "Successfully converted xml to csv.\n",
            "Generate `data/annotations/label_map.pbtxt`\n",
            "Successfully converted xml to csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# link for removing error - https://stackoverflow.com/questions/58258003/attributeerror-module-tensorflow-has-no-attribute-app\n",
        "\n",
        "# Generate `train.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "# tf.compat.v1.app.run----> for error.\n",
        "\n",
        "# Generate `test.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP_QoHVa6se-",
        "outputId": "3c01b996-5661-472b-eeea-f188c98b220f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecords: /content/object_detection_demo/data/annotations/train.record\n",
            "Successfully created the TFRecords: /content/object_detection_demo/data/annotations/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_record_fname = '/content/object_detection_demo/data/annotations/train.record'\n",
        "test_record_fname = '/content/object_detection_demo/data/annotations/test.record'\n",
        "label_map_pbtxt_fname = '/content/object_detection_demo/data/annotations/label_map.pbtxt'"
      ],
      "metadata": {
        "id": "44GvwJR77ne1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download base model"
      ],
      "metadata": {
        "id": "uiIuFJspW46m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmjzi3br8agS",
        "outputId": "597ffc0b-fcba-4c42-a864-de08e64e7b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "metadata": {
        "id": "piKumeZZW_Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWqF5In-Xk4z",
        "outputId": "2ac6a9ec-df7c-42b1-90c2-4fe66a8b7fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 24K\n",
            "drwxr-x---  4 345018 89939 4.0K Jul 11  2020 .\n",
            "drwxr-xr-x 23 root   root  4.0K Jul 25 06:48 ..\n",
            "drwxr-x---  2 345018 89939 4.0K Jul 10  2020 checkpoint\n",
            "-rw-r-----  1 345018 89939 4.5K Jul 11  2020 pipeline.config\n",
            "drwxr-x---  4 345018 89939 4.0K Jul 10  2020 saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"checkpoint/ckpt-0\")\n",
        "fine_tune_checkpoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yXlvlNvEX4lF",
        "outputId": "a7c94d6d-4d39-46ee-a14d-92c101063fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/checkpoint/ckpt-0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "test_record_fname = '/content/object_detection_demo/data/annotations/test.record'\n",
        "train_record_fname = '/content/object_detection_demo/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/object_detection_demo/data/annotations/label_map.pbtxt'\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"checkpoint/ckpt-0\")\n",
        "\n",
        "# !cp \"/content/models/research/object_detection/configs/tf2/\"{pipeline_file} {model_dir}\"/\"{pipeline_file}\n",
        "# pipeline_fname = os.path.join('/content/models/research/object_detection/configs/tf2/', pipeline_file)"
      ],
      "metadata": {
        "id": "LVGqzqoeGkwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEST_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GWwK8q8VHNBE",
        "outputId": "bd3785ba-2ed9-4c72-eb2c-3741a3961100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring a Training Pipeline"
      ],
      "metadata": {
        "id": "RDachqUZX78k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/configs/tf2/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "metadata": {
        "id": "1iHCrejyX535"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipeline_fname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9krRTbL77_fj",
        "outputId": "37c2f85a-1136-41af-f1a7-f69ccdc4a62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "metadata": {
        "id": "9rst9nzJX90z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train2017)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    # print(s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val2017)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    # Fine-tune checkpoint type\n",
        "    s = re.sub('fine_tune_checkpoint_type: \"classification\"', \n",
        "               'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "    \n",
        "    s = re.sub('num_epochs: [0-9]+',\n",
        "               'num_epochs: {}'.format(num_eval_steps), s)\n",
        "\n",
        "    f.write(s)"
      ],
      "metadata": {
        "id": "8jHw_V3TX_ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_record_fname"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wFFplWgCD0VX",
        "outputId": "c041cbf3-1ae7-4aae-9c0c-7874adf0e660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/object_detection_demo/data/annotations/train.record'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fine_tune_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQsp_Z96-dok",
        "outputId": "cd3eb5df-7329-4a71-a89a-b21db5211c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/pretrained_model/checkpoint/ckpt-0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd pipeline_fname"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgEss42Z-0s5",
        "outputId": "f9a2527a-e474-4bf5-e7ce-a7335f721543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_fname"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Lel_MGKhFwCn",
        "outputId": "add0273a-1c60-4746-fbec-468278e16c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat {pipeline_fname}"
      ],
      "metadata": {
        "id": "7NCg8FZlYB1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98437af3-be23-4ea8-9215-69ed4266e634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " # SSD with EfficientNet-b0 + BiFPN feature extractor,\n",
            "# shared box predictor and focal loss (a.k.a EfficientDet-d0).\n",
            "# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\n",
            "# See Lin et al, https://arxiv.org/abs/1708.02002\n",
            "# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.\n",
            "#\n",
            "# Train on TPU-8\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "    num_classes: 1\n",
            "    add_background_class: false\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    anchor_generator {\n",
            "      multiscale_anchor_generator {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        anchor_scale: 4.0\n",
            "        aspect_ratios: [1.0, 2.0, 0.5]\n",
            "        scales_per_octave: 3\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 512\n",
            "        max_dimension: 512\n",
            "        pad_to_max_dimension: true\n",
            "        }\n",
            "    }\n",
            "    box_predictor {\n",
            "      weight_shared_convolutional_box_predictor {\n",
            "        depth: 64\n",
            "        class_prediction_bias_init: -4.6\n",
            "        conv_hyperparams {\n",
            "          force_use_bias: true\n",
            "          activation: SWISH\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              stddev: 0.01\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            scale: true\n",
            "            decay: 0.99\n",
            "            epsilon: 0.001\n",
            "          }\n",
            "        }\n",
            "        num_layers_before_predictor: 3\n",
            "        kernel_size: 3\n",
            "        use_depthwise: true\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_efficientnet-b0_bifpn_keras'\n",
            "      bifpn {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        num_iterations: 3\n",
            "        num_filters: 64\n",
            "      }\n",
            "      conv_hyperparams {\n",
            "        force_use_bias: true\n",
            "        activation: SWISH\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          scale: true,\n",
            "          decay: 0.99,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          alpha: 0.25\n",
            "          gamma: 1.5\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.5\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/checkpoint/ckpt-0\"\n",
            "  fine_tune_checkpoint_version: V2\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  batch_size: 2\n",
            "  sync_replicas: true\n",
            "  startup_delay_steps: 0\n",
            "  replicas_to_aggregate: 8\n",
            "  use_bfloat16: true\n",
            "  num_steps: 5000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_scale_crop_and_pad_to_square {\n",
            "      output_size: 512\n",
            "      scale_min: 0.1\n",
            "      scale_max: 2.0\n",
            "    }\n",
            "  }\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 8e-2\n",
            "          total_steps: 300000\n",
            "          warmup_learning_rate: .001\n",
            "          warmup_steps: 2500\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo/data/annotations/train.record\"\n",
            "  }\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "  batch_size: 2;\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 50\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo/data/annotations/test.record\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "I4-iG88dYDVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd model_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpDNKzKoOAFn",
        "outputId": "7a4c6f8d-4736-48cd-a761-452b110c103a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Tensorboard(Optional)"
      ],
      "metadata": {
        "id": "4BQkZQe2YIUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujP9yz3ZYGcz",
        "outputId": "63ccc757-130c-494f-8b0a-39263fe08fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-25 06:48:53--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.161.241.46, 52.202.168.65, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.161.241.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  17.6MB/s    in 0.7s    \n",
            "\n",
            "2022-07-25 06:48:54 (17.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "metadata": {
        "id": "UFD5sBcYYJ39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "metadata": {
        "id": "1NeoZcYlYLEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZEkFyt2dYO1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Tensorboard link"
      ],
      "metadata": {
        "id": "D8kGIdGRYRCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zht3mf3iYROq",
        "outputId": "4f22f4db-cdbe-45a4-a2ad-e100987ce75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://f187-35-230-96-127.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2nZnZoDMYSwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "J-qPu5qsYeuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWInMKeCuPli",
        "outputId": "0cb22cfa-34c8-4175-887b-5b723a5affef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-25 06:49:18.809735: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0725 06:49:18.816366 139923294906240 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0725 06:49:18.819928 139923294906240 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0725 06:49:18.820073 139923294906240 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "I0725 06:49:18.826899 139923294906240 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0725 06:49:18.827026 139923294906240 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0725 06:49:18.827131 139923294906240 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0725 06:49:18.830916 139923294906240 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.849175 139923294906240 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.850870 139923294906240 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.853104 139923294906240 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.854029 139923294906240 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.861226 139923294906240 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.865095 139923294906240 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.870823 139923294906240 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0725 06:49:18.870920 139923294906240 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.883384 139923294906240 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.884241 139923294906240 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.885911 139923294906240 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.886753 139923294906240 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0725 06:49:18.960904 139923294906240 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0725 06:49:18.961007 139923294906240 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0725 06:49:19.197009 139923294906240 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0725 06:49:19.197151 139923294906240 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0725 06:49:19.424906 139923294906240 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0725 06:49:19.425043 139923294906240 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0725 06:49:19.778749 139923294906240 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0725 06:49:19.778923 139923294906240 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0725 06:49:20.135936 139923294906240 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0725 06:49:20.136094 139923294906240 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0725 06:49:20.613215 139923294906240 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0725 06:49:20.613375 139923294906240 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0725 06:49:20.733286 139923294906240 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0725 06:49:20.782300 139923294906240 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0725 06:49:20.821315 139923294906240 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/object_detection_demo/data/annotations/train.record']\n",
            "I0725 06:49:20.824887 139923294906240 dataset_builder.py:162] Reading unweighted datasets: ['/content/object_detection_demo/data/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/object_detection_demo/data/annotations/train.record']\n",
            "I0725 06:49:20.825098 139923294906240 dataset_builder.py:79] Reading record datasets for input file: ['/content/object_detection_demo/data/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0725 06:49:20.825191 139923294906240 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0725 06:49:20.825262 139923294906240 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0725 06:49:20.827140 139923294906240 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0725 06:49:20.845859 139923294906240 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0725 06:49:27.489830 139923294906240 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0725 06:49:31.262817 139923294906240 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0725 06:50:01.665554 139918284113664 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W0725 06:50:09.123766 139918284113664 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W0725 06:50:20.076175 139918284113664 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W0725 06:50:29.457046 139918284113664 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W0725 06:50:39.864287 139918284113664 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "INFO:tensorflow:Step 100 per-step time 0.718s\n",
            "I0725 06:51:13.102221 139923294906240 model_lib_v2.py:707] Step 100 per-step time 0.718s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3891076,\n",
            " 'Loss/localization_loss': 0.49624896,\n",
            " 'Loss/regularization_loss': 0.028355777,\n",
            " 'Loss/total_loss': 0.9137123,\n",
            " 'learning_rate': 0.00416}\n",
            "I0725 06:51:13.102542 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.3891076,\n",
            " 'Loss/localization_loss': 0.49624896,\n",
            " 'Loss/regularization_loss': 0.028355777,\n",
            " 'Loss/total_loss': 0.9137123,\n",
            " 'learning_rate': 0.00416}\n",
            "INFO:tensorflow:Step 200 per-step time 0.152s\n",
            "I0725 06:51:28.335103 139923294906240 model_lib_v2.py:707] Step 200 per-step time 0.152s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22221626,\n",
            " 'Loss/localization_loss': 0.3090473,\n",
            " 'Loss/regularization_loss': 0.028427867,\n",
            " 'Loss/total_loss': 0.5596914,\n",
            " 'learning_rate': 0.0073200003}\n",
            "I0725 06:51:28.335398 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.22221626,\n",
            " 'Loss/localization_loss': 0.3090473,\n",
            " 'Loss/regularization_loss': 0.028427867,\n",
            " 'Loss/total_loss': 0.5596914,\n",
            " 'learning_rate': 0.0073200003}\n",
            "INFO:tensorflow:Step 300 per-step time 0.153s\n",
            "I0725 06:51:43.641737 139923294906240 model_lib_v2.py:707] Step 300 per-step time 0.153s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4117896,\n",
            " 'Loss/localization_loss': 0.2063055,\n",
            " 'Loss/regularization_loss': 0.028628284,\n",
            " 'Loss/total_loss': 0.6467234,\n",
            " 'learning_rate': 0.010480001}\n",
            "I0725 06:51:43.642046 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.4117896,\n",
            " 'Loss/localization_loss': 0.2063055,\n",
            " 'Loss/regularization_loss': 0.028628284,\n",
            " 'Loss/total_loss': 0.6467234,\n",
            " 'learning_rate': 0.010480001}\n",
            "INFO:tensorflow:Step 400 per-step time 0.154s\n",
            "I0725 06:51:59.023453 139923294906240 model_lib_v2.py:707] Step 400 per-step time 0.154s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.5716453,\n",
            " 'Loss/localization_loss': 0.43002936,\n",
            " 'Loss/regularization_loss': 0.028853886,\n",
            " 'Loss/total_loss': 1.0305285,\n",
            " 'learning_rate': 0.0136400005}\n",
            "I0725 06:51:59.023770 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.5716453,\n",
            " 'Loss/localization_loss': 0.43002936,\n",
            " 'Loss/regularization_loss': 0.028853886,\n",
            " 'Loss/total_loss': 1.0305285,\n",
            " 'learning_rate': 0.0136400005}\n",
            "INFO:tensorflow:Step 500 per-step time 0.155s\n",
            "I0725 06:52:14.559577 139923294906240 model_lib_v2.py:707] Step 500 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.5805956,\n",
            " 'Loss/localization_loss': 0.1881903,\n",
            " 'Loss/regularization_loss': 0.029462984,\n",
            " 'Loss/total_loss': 0.7982489,\n",
            " 'learning_rate': 0.016800001}\n",
            "I0725 06:52:14.559918 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.5805956,\n",
            " 'Loss/localization_loss': 0.1881903,\n",
            " 'Loss/regularization_loss': 0.029462984,\n",
            " 'Loss/total_loss': 0.7982489,\n",
            " 'learning_rate': 0.016800001}\n",
            "INFO:tensorflow:Step 600 per-step time 0.155s\n",
            "I0725 06:52:30.099905 139923294906240 model_lib_v2.py:707] Step 600 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.7839927,\n",
            " 'Loss/localization_loss': 0.56941533,\n",
            " 'Loss/regularization_loss': 0.03416597,\n",
            " 'Loss/total_loss': 1.3875741,\n",
            " 'learning_rate': 0.019960001}\n",
            "I0725 06:52:30.100200 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.7839927,\n",
            " 'Loss/localization_loss': 0.56941533,\n",
            " 'Loss/regularization_loss': 0.03416597,\n",
            " 'Loss/total_loss': 1.3875741,\n",
            " 'learning_rate': 0.019960001}\n",
            "INFO:tensorflow:Step 700 per-step time 0.156s\n",
            "I0725 06:52:45.675589 139923294906240 model_lib_v2.py:707] Step 700 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.5247187,\n",
            " 'Loss/localization_loss': 0.36160794,\n",
            " 'Loss/regularization_loss': 0.034440313,\n",
            " 'Loss/total_loss': 0.920767,\n",
            " 'learning_rate': 0.023120001}\n",
            "I0725 06:52:45.675910 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.5247187,\n",
            " 'Loss/localization_loss': 0.36160794,\n",
            " 'Loss/regularization_loss': 0.034440313,\n",
            " 'Loss/total_loss': 0.920767,\n",
            " 'learning_rate': 0.023120001}\n",
            "INFO:tensorflow:Step 800 per-step time 0.156s\n",
            "I0725 06:53:01.251277 139923294906240 model_lib_v2.py:707] Step 800 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.45739773,\n",
            " 'Loss/localization_loss': 0.27237874,\n",
            " 'Loss/regularization_loss': 0.034620386,\n",
            " 'Loss/total_loss': 0.7643969,\n",
            " 'learning_rate': 0.02628}\n",
            "I0725 06:53:01.251563 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.45739773,\n",
            " 'Loss/localization_loss': 0.27237874,\n",
            " 'Loss/regularization_loss': 0.034620386,\n",
            " 'Loss/total_loss': 0.7643969,\n",
            " 'learning_rate': 0.02628}\n",
            "INFO:tensorflow:Step 900 per-step time 0.156s\n",
            "I0725 06:53:16.863425 139923294906240 model_lib_v2.py:707] Step 900 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.40431166,\n",
            " 'Loss/localization_loss': 0.25470757,\n",
            " 'Loss/regularization_loss': 0.034805827,\n",
            " 'Loss/total_loss': 0.69382507,\n",
            " 'learning_rate': 0.02944}\n",
            "I0725 06:53:16.863731 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.40431166,\n",
            " 'Loss/localization_loss': 0.25470757,\n",
            " 'Loss/regularization_loss': 0.034805827,\n",
            " 'Loss/total_loss': 0.69382507,\n",
            " 'learning_rate': 0.02944}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.155s\n",
            "I0725 06:53:32.332830 139923294906240 model_lib_v2.py:707] Step 1000 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3653535,\n",
            " 'Loss/localization_loss': 0.19390216,\n",
            " 'Loss/regularization_loss': 0.03495176,\n",
            " 'Loss/total_loss': 0.5942074,\n",
            " 'learning_rate': 0.0326}\n",
            "I0725 06:53:32.333109 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.3653535,\n",
            " 'Loss/localization_loss': 0.19390216,\n",
            " 'Loss/regularization_loss': 0.03495176,\n",
            " 'Loss/total_loss': 0.5942074,\n",
            " 'learning_rate': 0.0326}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.168s\n",
            "I0725 06:53:49.087727 139923294906240 model_lib_v2.py:707] Step 1100 per-step time 0.168s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3583151,\n",
            " 'Loss/localization_loss': 0.24345453,\n",
            " 'Loss/regularization_loss': 0.035190165,\n",
            " 'Loss/total_loss': 0.6369598,\n",
            " 'learning_rate': 0.03576}\n",
            "I0725 06:53:49.088023 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.3583151,\n",
            " 'Loss/localization_loss': 0.24345453,\n",
            " 'Loss/regularization_loss': 0.035190165,\n",
            " 'Loss/total_loss': 0.6369598,\n",
            " 'learning_rate': 0.03576}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.156s\n",
            "I0725 06:54:04.638155 139923294906240 model_lib_v2.py:707] Step 1200 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21362554,\n",
            " 'Loss/localization_loss': 0.13856141,\n",
            " 'Loss/regularization_loss': 0.035435263,\n",
            " 'Loss/total_loss': 0.3876222,\n",
            " 'learning_rate': 0.03892}\n",
            "I0725 06:54:04.638478 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.21362554,\n",
            " 'Loss/localization_loss': 0.13856141,\n",
            " 'Loss/regularization_loss': 0.035435263,\n",
            " 'Loss/total_loss': 0.3876222,\n",
            " 'learning_rate': 0.03892}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.156s\n",
            "I0725 06:54:20.268014 139923294906240 model_lib_v2.py:707] Step 1300 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.32851452,\n",
            " 'Loss/localization_loss': 0.19134268,\n",
            " 'Loss/regularization_loss': 0.035724342,\n",
            " 'Loss/total_loss': 0.5555815,\n",
            " 'learning_rate': 0.04208}\n",
            "I0725 06:54:20.268332 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.32851452,\n",
            " 'Loss/localization_loss': 0.19134268,\n",
            " 'Loss/regularization_loss': 0.035724342,\n",
            " 'Loss/total_loss': 0.5555815,\n",
            " 'learning_rate': 0.04208}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.155s\n",
            "I0725 06:54:35.786872 139923294906240 model_lib_v2.py:707] Step 1400 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.36127564,\n",
            " 'Loss/localization_loss': 0.21573542,\n",
            " 'Loss/regularization_loss': 0.036007017,\n",
            " 'Loss/total_loss': 0.61301804,\n",
            " 'learning_rate': 0.04524}\n",
            "I0725 06:54:35.787167 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.36127564,\n",
            " 'Loss/localization_loss': 0.21573542,\n",
            " 'Loss/regularization_loss': 0.036007017,\n",
            " 'Loss/total_loss': 0.61301804,\n",
            " 'learning_rate': 0.04524}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.155s\n",
            "I0725 06:54:51.246890 139923294906240 model_lib_v2.py:707] Step 1500 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3254748,\n",
            " 'Loss/localization_loss': 0.21314429,\n",
            " 'Loss/regularization_loss': 0.036250796,\n",
            " 'Loss/total_loss': 0.5748699,\n",
            " 'learning_rate': 0.0484}\n",
            "I0725 06:54:51.247189 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.3254748,\n",
            " 'Loss/localization_loss': 0.21314429,\n",
            " 'Loss/regularization_loss': 0.036250796,\n",
            " 'Loss/total_loss': 0.5748699,\n",
            " 'learning_rate': 0.0484}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.156s\n",
            "I0725 06:55:06.866534 139923294906240 model_lib_v2.py:707] Step 1600 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.36712465,\n",
            " 'Loss/localization_loss': 0.39800254,\n",
            " 'Loss/regularization_loss': 0.036593042,\n",
            " 'Loss/total_loss': 0.8017202,\n",
            " 'learning_rate': 0.05156}\n",
            "I0725 06:55:06.866867 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.36712465,\n",
            " 'Loss/localization_loss': 0.39800254,\n",
            " 'Loss/regularization_loss': 0.036593042,\n",
            " 'Loss/total_loss': 0.8017202,\n",
            " 'learning_rate': 0.05156}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.154s\n",
            "I0725 06:55:22.273086 139923294906240 model_lib_v2.py:707] Step 1700 per-step time 0.154s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16753961,\n",
            " 'Loss/localization_loss': 0.049658436,\n",
            " 'Loss/regularization_loss': 0.036918957,\n",
            " 'Loss/total_loss': 0.254117,\n",
            " 'learning_rate': 0.05472}\n",
            "I0725 06:55:22.273375 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.16753961,\n",
            " 'Loss/localization_loss': 0.049658436,\n",
            " 'Loss/regularization_loss': 0.036918957,\n",
            " 'Loss/total_loss': 0.254117,\n",
            " 'learning_rate': 0.05472}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.156s\n",
            "I0725 06:55:37.845525 139923294906240 model_lib_v2.py:707] Step 1800 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.37059644,\n",
            " 'Loss/localization_loss': 0.18334734,\n",
            " 'Loss/regularization_loss': 0.0372844,\n",
            " 'Loss/total_loss': 0.5912281,\n",
            " 'learning_rate': 0.05788}\n",
            "I0725 06:55:37.845817 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.37059644,\n",
            " 'Loss/localization_loss': 0.18334734,\n",
            " 'Loss/regularization_loss': 0.0372844,\n",
            " 'Loss/total_loss': 0.5912281,\n",
            " 'learning_rate': 0.05788}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.156s\n",
            "I0725 06:55:53.432819 139923294906240 model_lib_v2.py:707] Step 1900 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2910318,\n",
            " 'Loss/localization_loss': 0.25769082,\n",
            " 'Loss/regularization_loss': 0.03773987,\n",
            " 'Loss/total_loss': 0.5864625,\n",
            " 'learning_rate': 0.06104}\n",
            "I0725 06:55:53.433098 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.2910318,\n",
            " 'Loss/localization_loss': 0.25769082,\n",
            " 'Loss/regularization_loss': 0.03773987,\n",
            " 'Loss/total_loss': 0.5864625,\n",
            " 'learning_rate': 0.06104}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.156s\n",
            "I0725 06:56:08.992813 139923294906240 model_lib_v2.py:707] Step 2000 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.46294898,\n",
            " 'Loss/localization_loss': 0.4089364,\n",
            " 'Loss/regularization_loss': 0.0383261,\n",
            " 'Loss/total_loss': 0.9102115,\n",
            " 'learning_rate': 0.06420001}\n",
            "I0725 06:56:08.993104 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.46294898,\n",
            " 'Loss/localization_loss': 0.4089364,\n",
            " 'Loss/regularization_loss': 0.0383261,\n",
            " 'Loss/total_loss': 0.9102115,\n",
            " 'learning_rate': 0.06420001}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.165s\n",
            "I0725 06:56:25.445036 139923294906240 model_lib_v2.py:707] Step 2100 per-step time 0.165s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23398037,\n",
            " 'Loss/localization_loss': 0.07360237,\n",
            " 'Loss/regularization_loss': 0.038845934,\n",
            " 'Loss/total_loss': 0.34642866,\n",
            " 'learning_rate': 0.067360006}\n",
            "I0725 06:56:25.445355 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.23398037,\n",
            " 'Loss/localization_loss': 0.07360237,\n",
            " 'Loss/regularization_loss': 0.038845934,\n",
            " 'Loss/total_loss': 0.34642866,\n",
            " 'learning_rate': 0.067360006}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.157s\n",
            "I0725 06:56:41.100972 139923294906240 model_lib_v2.py:707] Step 2200 per-step time 0.157s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19293115,\n",
            " 'Loss/localization_loss': 0.093575984,\n",
            " 'Loss/regularization_loss': 0.03928191,\n",
            " 'Loss/total_loss': 0.32578903,\n",
            " 'learning_rate': 0.070520006}\n",
            "I0725 06:56:41.101274 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.19293115,\n",
            " 'Loss/localization_loss': 0.093575984,\n",
            " 'Loss/regularization_loss': 0.03928191,\n",
            " 'Loss/total_loss': 0.32578903,\n",
            " 'learning_rate': 0.070520006}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.154s\n",
            "I0725 06:56:56.541309 139923294906240 model_lib_v2.py:707] Step 2300 per-step time 0.154s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15922809,\n",
            " 'Loss/localization_loss': 0.07248351,\n",
            " 'Loss/regularization_loss': 0.03967911,\n",
            " 'Loss/total_loss': 0.2713907,\n",
            " 'learning_rate': 0.073680006}\n",
            "I0725 06:56:56.541617 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.15922809,\n",
            " 'Loss/localization_loss': 0.07248351,\n",
            " 'Loss/regularization_loss': 0.03967911,\n",
            " 'Loss/total_loss': 0.2713907,\n",
            " 'learning_rate': 0.073680006}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.155s\n",
            "I0725 06:57:12.057565 139923294906240 model_lib_v2.py:707] Step 2400 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3259624,\n",
            " 'Loss/localization_loss': 0.1586306,\n",
            " 'Loss/regularization_loss': 0.041088708,\n",
            " 'Loss/total_loss': 0.5256817,\n",
            " 'learning_rate': 0.076840006}\n",
            "I0725 06:57:12.057879 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.3259624,\n",
            " 'Loss/localization_loss': 0.1586306,\n",
            " 'Loss/regularization_loss': 0.041088708,\n",
            " 'Loss/total_loss': 0.5256817,\n",
            " 'learning_rate': 0.076840006}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.155s\n",
            "I0725 06:57:27.514070 139923294906240 model_lib_v2.py:707] Step 2500 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.34745786,\n",
            " 'Loss/localization_loss': 0.14481577,\n",
            " 'Loss/regularization_loss': 0.041579433,\n",
            " 'Loss/total_loss': 0.53385305,\n",
            " 'learning_rate': 0.08}\n",
            "I0725 06:57:27.514372 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.34745786,\n",
            " 'Loss/localization_loss': 0.14481577,\n",
            " 'Loss/regularization_loss': 0.041579433,\n",
            " 'Loss/total_loss': 0.53385305,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.155s\n",
            "I0725 06:57:43.020064 139923294906240 model_lib_v2.py:707] Step 2600 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15557966,\n",
            " 'Loss/localization_loss': 0.09630076,\n",
            " 'Loss/regularization_loss': 0.04202676,\n",
            " 'Loss/total_loss': 0.29390717,\n",
            " 'learning_rate': 0.079999976}\n",
            "I0725 06:57:43.020366 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.15557966,\n",
            " 'Loss/localization_loss': 0.09630076,\n",
            " 'Loss/regularization_loss': 0.04202676,\n",
            " 'Loss/total_loss': 0.29390717,\n",
            " 'learning_rate': 0.079999976}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.154s\n",
            "I0725 06:57:58.449339 139923294906240 model_lib_v2.py:707] Step 2700 per-step time 0.154s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18174449,\n",
            " 'Loss/localization_loss': 0.07371154,\n",
            " 'Loss/regularization_loss': 0.04236532,\n",
            " 'Loss/total_loss': 0.29782134,\n",
            " 'learning_rate': 0.07999991}\n",
            "I0725 06:57:58.449623 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.18174449,\n",
            " 'Loss/localization_loss': 0.07371154,\n",
            " 'Loss/regularization_loss': 0.04236532,\n",
            " 'Loss/total_loss': 0.29782134,\n",
            " 'learning_rate': 0.07999991}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.156s\n",
            "I0725 06:58:14.036945 139923294906240 model_lib_v2.py:707] Step 2800 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2743968,\n",
            " 'Loss/localization_loss': 0.12067138,\n",
            " 'Loss/regularization_loss': 0.042893186,\n",
            " 'Loss/total_loss': 0.43796134,\n",
            " 'learning_rate': 0.0799998}\n",
            "I0725 06:58:14.037270 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.2743968,\n",
            " 'Loss/localization_loss': 0.12067138,\n",
            " 'Loss/regularization_loss': 0.042893186,\n",
            " 'Loss/total_loss': 0.43796134,\n",
            " 'learning_rate': 0.0799998}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.156s\n",
            "I0725 06:58:29.621016 139923294906240 model_lib_v2.py:707] Step 2900 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.36292437,\n",
            " 'Loss/localization_loss': 0.16797695,\n",
            " 'Loss/regularization_loss': 0.04335807,\n",
            " 'Loss/total_loss': 0.5742594,\n",
            " 'learning_rate': 0.07999964}\n",
            "I0725 06:58:29.621303 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.36292437,\n",
            " 'Loss/localization_loss': 0.16797695,\n",
            " 'Loss/regularization_loss': 0.04335807,\n",
            " 'Loss/total_loss': 0.5742594,\n",
            " 'learning_rate': 0.07999964}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.156s\n",
            "I0725 06:58:45.190638 139923294906240 model_lib_v2.py:707] Step 3000 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18094553,\n",
            " 'Loss/localization_loss': 0.06758891,\n",
            " 'Loss/regularization_loss': 0.043623183,\n",
            " 'Loss/total_loss': 0.29215762,\n",
            " 'learning_rate': 0.07999944}\n",
            "I0725 06:58:45.190944 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.18094553,\n",
            " 'Loss/localization_loss': 0.06758891,\n",
            " 'Loss/regularization_loss': 0.043623183,\n",
            " 'Loss/total_loss': 0.29215762,\n",
            " 'learning_rate': 0.07999944}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.163s\n",
            "I0725 06:59:01.477618 139923294906240 model_lib_v2.py:707] Step 3100 per-step time 0.163s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1799566,\n",
            " 'Loss/localization_loss': 0.100432836,\n",
            " 'Loss/regularization_loss': 0.043989837,\n",
            " 'Loss/total_loss': 0.32437927,\n",
            " 'learning_rate': 0.07999919}\n",
            "I0725 06:59:01.477931 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.1799566,\n",
            " 'Loss/localization_loss': 0.100432836,\n",
            " 'Loss/regularization_loss': 0.043989837,\n",
            " 'Loss/total_loss': 0.32437927,\n",
            " 'learning_rate': 0.07999919}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.156s\n",
            "I0725 06:59:17.061743 139923294906240 model_lib_v2.py:707] Step 3200 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2586582,\n",
            " 'Loss/localization_loss': 0.17218728,\n",
            " 'Loss/regularization_loss': 0.044282835,\n",
            " 'Loss/total_loss': 0.47512832,\n",
            " 'learning_rate': 0.0799989}\n",
            "I0725 06:59:17.062046 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.2586582,\n",
            " 'Loss/localization_loss': 0.17218728,\n",
            " 'Loss/regularization_loss': 0.044282835,\n",
            " 'Loss/total_loss': 0.47512832,\n",
            " 'learning_rate': 0.0799989}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.155s\n",
            "I0725 06:59:32.523891 139923294906240 model_lib_v2.py:707] Step 3300 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14501286,\n",
            " 'Loss/localization_loss': 0.05927666,\n",
            " 'Loss/regularization_loss': 0.04451304,\n",
            " 'Loss/total_loss': 0.24880254,\n",
            " 'learning_rate': 0.07999857}\n",
            "I0725 06:59:32.524174 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.14501286,\n",
            " 'Loss/localization_loss': 0.05927666,\n",
            " 'Loss/regularization_loss': 0.04451304,\n",
            " 'Loss/total_loss': 0.24880254,\n",
            " 'learning_rate': 0.07999857}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.155s\n",
            "I0725 06:59:48.051531 139923294906240 model_lib_v2.py:707] Step 3400 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25962365,\n",
            " 'Loss/localization_loss': 0.1422682,\n",
            " 'Loss/regularization_loss': 0.044718258,\n",
            " 'Loss/total_loss': 0.4466101,\n",
            " 'learning_rate': 0.07999819}\n",
            "I0725 06:59:48.051820 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.25962365,\n",
            " 'Loss/localization_loss': 0.1422682,\n",
            " 'Loss/regularization_loss': 0.044718258,\n",
            " 'Loss/total_loss': 0.4466101,\n",
            " 'learning_rate': 0.07999819}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.154s\n",
            "I0725 07:00:03.441807 139923294906240 model_lib_v2.py:707] Step 3500 per-step time 0.154s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17933685,\n",
            " 'Loss/localization_loss': 0.06933386,\n",
            " 'Loss/regularization_loss': 0.044904687,\n",
            " 'Loss/total_loss': 0.29357538,\n",
            " 'learning_rate': 0.07999776}\n",
            "I0725 07:00:03.442102 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.17933685,\n",
            " 'Loss/localization_loss': 0.06933386,\n",
            " 'Loss/regularization_loss': 0.044904687,\n",
            " 'Loss/total_loss': 0.29357538,\n",
            " 'learning_rate': 0.07999776}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.156s\n",
            "I0725 07:00:19.031128 139923294906240 model_lib_v2.py:707] Step 3600 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.297721,\n",
            " 'Loss/localization_loss': 0.08624225,\n",
            " 'Loss/regularization_loss': 0.045117125,\n",
            " 'Loss/total_loss': 0.42908037,\n",
            " 'learning_rate': 0.0799973}\n",
            "I0725 07:00:19.031461 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.297721,\n",
            " 'Loss/localization_loss': 0.08624225,\n",
            " 'Loss/regularization_loss': 0.045117125,\n",
            " 'Loss/total_loss': 0.42908037,\n",
            " 'learning_rate': 0.0799973}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.156s\n",
            "I0725 07:00:34.648895 139923294906240 model_lib_v2.py:707] Step 3700 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10976436,\n",
            " 'Loss/localization_loss': 0.06025346,\n",
            " 'Loss/regularization_loss': 0.0452174,\n",
            " 'Loss/total_loss': 0.21523522,\n",
            " 'learning_rate': 0.07999679}\n",
            "I0725 07:00:34.649179 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.10976436,\n",
            " 'Loss/localization_loss': 0.06025346,\n",
            " 'Loss/regularization_loss': 0.0452174,\n",
            " 'Loss/total_loss': 0.21523522,\n",
            " 'learning_rate': 0.07999679}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.155s\n",
            "I0725 07:00:50.143005 139923294906240 model_lib_v2.py:707] Step 3800 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2546218,\n",
            " 'Loss/localization_loss': 0.085144006,\n",
            " 'Loss/regularization_loss': 0.045451753,\n",
            " 'Loss/total_loss': 0.38521758,\n",
            " 'learning_rate': 0.07999623}\n",
            "I0725 07:00:50.143313 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.2546218,\n",
            " 'Loss/localization_loss': 0.085144006,\n",
            " 'Loss/regularization_loss': 0.045451753,\n",
            " 'Loss/total_loss': 0.38521758,\n",
            " 'learning_rate': 0.07999623}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.156s\n",
            "I0725 07:01:05.697535 139923294906240 model_lib_v2.py:707] Step 3900 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21017316,\n",
            " 'Loss/localization_loss': 0.09364366,\n",
            " 'Loss/regularization_loss': 0.04565329,\n",
            " 'Loss/total_loss': 0.3494701,\n",
            " 'learning_rate': 0.07999563}\n",
            "I0725 07:01:05.697828 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.21017316,\n",
            " 'Loss/localization_loss': 0.09364366,\n",
            " 'Loss/regularization_loss': 0.04565329,\n",
            " 'Loss/total_loss': 0.3494701,\n",
            " 'learning_rate': 0.07999563}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.155s\n",
            "I0725 07:01:21.186649 139923294906240 model_lib_v2.py:707] Step 4000 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17438969,\n",
            " 'Loss/localization_loss': 0.07962819,\n",
            " 'Loss/regularization_loss': 0.045857225,\n",
            " 'Loss/total_loss': 0.2998751,\n",
            " 'learning_rate': 0.079994984}\n",
            "I0725 07:01:21.186930 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.17438969,\n",
            " 'Loss/localization_loss': 0.07962819,\n",
            " 'Loss/regularization_loss': 0.045857225,\n",
            " 'Loss/total_loss': 0.2998751,\n",
            " 'learning_rate': 0.079994984}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.163s\n",
            "I0725 07:01:37.493880 139923294906240 model_lib_v2.py:707] Step 4100 per-step time 0.163s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17369695,\n",
            " 'Loss/localization_loss': 0.05228735,\n",
            " 'Loss/regularization_loss': 0.04604041,\n",
            " 'Loss/total_loss': 0.27202472,\n",
            " 'learning_rate': 0.07999428}\n",
            "I0725 07:01:37.494169 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.17369695,\n",
            " 'Loss/localization_loss': 0.05228735,\n",
            " 'Loss/regularization_loss': 0.04604041,\n",
            " 'Loss/total_loss': 0.27202472,\n",
            " 'learning_rate': 0.07999428}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.156s\n",
            "I0725 07:01:53.089416 139923294906240 model_lib_v2.py:707] Step 4200 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17023067,\n",
            " 'Loss/localization_loss': 0.092957616,\n",
            " 'Loss/regularization_loss': 0.046199355,\n",
            " 'Loss/total_loss': 0.30938765,\n",
            " 'learning_rate': 0.07999355}\n",
            "I0725 07:01:53.089741 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.17023067,\n",
            " 'Loss/localization_loss': 0.092957616,\n",
            " 'Loss/regularization_loss': 0.046199355,\n",
            " 'Loss/total_loss': 0.30938765,\n",
            " 'learning_rate': 0.07999355}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.156s\n",
            "I0725 07:02:08.675049 139923294906240 model_lib_v2.py:707] Step 4300 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16499914,\n",
            " 'Loss/localization_loss': 0.039226703,\n",
            " 'Loss/regularization_loss': 0.046426587,\n",
            " 'Loss/total_loss': 0.25065243,\n",
            " 'learning_rate': 0.07999277}\n",
            "I0725 07:02:08.675335 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.16499914,\n",
            " 'Loss/localization_loss': 0.039226703,\n",
            " 'Loss/regularization_loss': 0.046426587,\n",
            " 'Loss/total_loss': 0.25065243,\n",
            " 'learning_rate': 0.07999277}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.155s\n",
            "I0725 07:02:24.181045 139923294906240 model_lib_v2.py:707] Step 4400 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1611702,\n",
            " 'Loss/localization_loss': 0.15480466,\n",
            " 'Loss/regularization_loss': 0.046670325,\n",
            " 'Loss/total_loss': 0.36264518,\n",
            " 'learning_rate': 0.07999195}\n",
            "I0725 07:02:24.181340 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.1611702,\n",
            " 'Loss/localization_loss': 0.15480466,\n",
            " 'Loss/regularization_loss': 0.046670325,\n",
            " 'Loss/total_loss': 0.36264518,\n",
            " 'learning_rate': 0.07999195}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.156s\n",
            "I0725 07:02:39.826354 139923294906240 model_lib_v2.py:707] Step 4500 per-step time 0.156s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19188452,\n",
            " 'Loss/localization_loss': 0.18076319,\n",
            " 'Loss/regularization_loss': 0.04689929,\n",
            " 'Loss/total_loss': 0.419547,\n",
            " 'learning_rate': 0.07999108}\n",
            "I0725 07:02:39.826683 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.19188452,\n",
            " 'Loss/localization_loss': 0.18076319,\n",
            " 'Loss/regularization_loss': 0.04689929,\n",
            " 'Loss/total_loss': 0.419547,\n",
            " 'learning_rate': 0.07999108}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.155s\n",
            "I0725 07:02:55.328051 139923294906240 model_lib_v2.py:707] Step 4600 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21863791,\n",
            " 'Loss/localization_loss': 0.10731706,\n",
            " 'Loss/regularization_loss': 0.04700529,\n",
            " 'Loss/total_loss': 0.37296027,\n",
            " 'learning_rate': 0.07999016}\n",
            "I0725 07:02:55.328333 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.21863791,\n",
            " 'Loss/localization_loss': 0.10731706,\n",
            " 'Loss/regularization_loss': 0.04700529,\n",
            " 'Loss/total_loss': 0.37296027,\n",
            " 'learning_rate': 0.07999016}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.155s\n",
            "I0725 07:03:10.864224 139923294906240 model_lib_v2.py:707] Step 4700 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09161922,\n",
            " 'Loss/localization_loss': 0.061843425,\n",
            " 'Loss/regularization_loss': 0.047160186,\n",
            " 'Loss/total_loss': 0.20062283,\n",
            " 'learning_rate': 0.0799892}\n",
            "I0725 07:03:10.864541 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.09161922,\n",
            " 'Loss/localization_loss': 0.061843425,\n",
            " 'Loss/regularization_loss': 0.047160186,\n",
            " 'Loss/total_loss': 0.20062283,\n",
            " 'learning_rate': 0.0799892}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.155s\n",
            "I0725 07:03:26.352864 139923294906240 model_lib_v2.py:707] Step 4800 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17144136,\n",
            " 'Loss/localization_loss': 0.060659453,\n",
            " 'Loss/regularization_loss': 0.047326952,\n",
            " 'Loss/total_loss': 0.27942777,\n",
            " 'learning_rate': 0.079988204}\n",
            "I0725 07:03:26.353176 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.17144136,\n",
            " 'Loss/localization_loss': 0.060659453,\n",
            " 'Loss/regularization_loss': 0.047326952,\n",
            " 'Loss/total_loss': 0.27942777,\n",
            " 'learning_rate': 0.079988204}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.154s\n",
            "I0725 07:03:41.750918 139923294906240 model_lib_v2.py:707] Step 4900 per-step time 0.154s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11276117,\n",
            " 'Loss/localization_loss': 0.04293789,\n",
            " 'Loss/regularization_loss': 0.047364686,\n",
            " 'Loss/total_loss': 0.20306374,\n",
            " 'learning_rate': 0.07998715}\n",
            "I0725 07:03:41.751199 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.11276117,\n",
            " 'Loss/localization_loss': 0.04293789,\n",
            " 'Loss/regularization_loss': 0.047364686,\n",
            " 'Loss/total_loss': 0.20306374,\n",
            " 'learning_rate': 0.07998715}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.155s\n",
            "I0725 07:03:57.229111 139923294906240 model_lib_v2.py:707] Step 5000 per-step time 0.155s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15939897,\n",
            " 'Loss/localization_loss': 0.08662165,\n",
            " 'Loss/regularization_loss': 0.047651492,\n",
            " 'Loss/total_loss': 0.2936721,\n",
            " 'learning_rate': 0.07998606}\n",
            "I0725 07:03:57.229402 139923294906240 model_lib_v2.py:708] {'Loss/classification_loss': 0.15939897,\n",
            " 'Loss/localization_loss': 0.08662165,\n",
            " 'Loss/regularization_loss': 0.047651492,\n",
            " 'Loss/total_loss': 0.2936721,\n",
            " 'learning_rate': 0.07998606}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %tensorflow_version 2.x"
      ],
      "metadata": {
        "id": "X41w8j7ei8OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {model_dir}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK3nLBs1wPwq",
        "outputId": "2fb3a37f-a81f-4818-ea72-6e634f3d7218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint\t\t    ckpt-3.data-00000-of-00001\tckpt-5.index\n",
            "ckpt-1.data-00000-of-00001  ckpt-3.index\t\tckpt-6.index\n",
            "ckpt-1.index\t\t    ckpt-4.data-00000-of-00001\tmodel.ckpt-\n",
            "ckpt-2.data-00000-of-00001  ckpt-4.index\t\ttrain\n",
            "ckpt-2.index\t\t    ckpt-5.data-00000-of-00001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4q9ckFORF3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!arbitrary_image_stylization_with_weights \\\n",
        "  --maximum_styles_to_evaluate=1000 --checkpoint=checkpoint/model.ckpt \\\n",
        "  --output_dir=images/output/  \\\n",
        "  --style_images_paths=images/style_images/ \\\n",
        "  --content_images_paths=images/content_images/ \\\n",
        "  --image_size=256 \\\n",
        "  --content_square_crop=False \\\n",
        "  --style_image_size=256 \\\n",
        "  --style_square_crop=False \\\n",
        "  --logtostderr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kjuGBTURF8I",
        "outputId": "d0032a77-10b5-49f1-d4de-587f76a3d239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: arbitrary_image_stylization_with_weights: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/models/research/training/ckpt-6.data-00000-of-00001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl2vN79iNErj",
        "outputId": "9f4596fe-c8c7-40fb-f43f-2247bcf62d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/training/ckpt-6.data-00000-of-00001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pLRQ8Z6hL3S_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}